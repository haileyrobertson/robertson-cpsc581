{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 9: Support Vector Machines**\n",
        "\n",
        "*CPSC 381/581: Machine Learning*\n",
        "\n",
        "*Yale University*\n",
        "\n",
        "*Instructor: Alex Wong*\n",
        "\n",
        "\n",
        "**Prerequisites**:\n",
        "\n",
        "1. Enable Google Colaboratory as an app on your Google Drive account\n",
        "\n",
        "2. Create a new Google Colab notebook, this will also create a \"Colab Notebooks\" directory under \"MyDrive\" i.e.\n",
        "```\n",
        "/content/drive/MyDrive/Colab Notebooks\n",
        "```\n",
        "\n",
        "3. Create the following directory structure in your Google Drive\n",
        "```\n",
        "/content/drive/MyDrive/Colab Notebooks/CPSC 381-581: Machine Learning/Exercises\n",
        "```\n",
        "\n",
        "4. Move the 09_exercise_support_vector_machines.ipynb into\n",
        "```\n",
        "/content/drive/MyDrive/Colab Notebooks/CPSC 381-581: Machine Learning/Exercises\n",
        "```\n",
        "so that its absolute path is\n",
        "```\n",
        "/content/drive/MyDrive/Colab Notebooks/CPSC 381-581: Machine Learning/Exercises/09_exercise_support_vector_machines.ipynb\n",
        "```\n",
        "\n",
        "In this exercise, we will optimize a perceptron, logistic regression, and support vector machine on 4 datasets. We can compare classification accuracy across all the datasets to see which method is the best.\n",
        "\n",
        "\n",
        "**Submission**:\n",
        "\n",
        "1. Implement all TODOs in the code blocks below.\n",
        "\n",
        "2. Report your validation scores for each method averaged over 10 trials.\n",
        "\n",
        "```\n",
        "Report validation scores for each method averaged over 10 trials here.\n",
        "\n",
        "\n",
        "```\n",
        "\n",
        "3. List any collaborators.\n",
        "\n",
        "```\n",
        "Collaborators: Doe, Jane (Please write names in <Last Name, First Name> format)\n",
        "\n",
        "Collaboration details: Discussed ... implementation details with Jane Doe.\n",
        "```"
      ],
      "metadata": {
        "id": "_0fsGaVMMpwG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import packages"
      ],
      "metadata": {
        "id": "wxeZsiCGC0J8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uumvcyiQ-k21"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import sklearn.datasets as skdata\n",
        "import sklearn.metrics as skmetrics\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from matplotlib import pyplot as plt\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(action='ignore')\n",
        "np.random.seed = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize the decision boundary and support vectors of different classifiers"
      ],
      "metadata": {
        "id": "LrETY5Q8WhWA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate synthetic data\n",
        "X, y = skdata.make_classification(\n",
        "    n_features=2,\n",
        "    n_classes=2,\n",
        "    n_redundant=0,\n",
        "    n_clusters_per_class=2,\n",
        "    n_samples=100,\n",
        "    class_sep=1.5,\n",
        "    random_state=1)\n",
        "\n",
        "methods = [\n",
        "    'perceptron',\n",
        "    'logistic_regression',\n",
        "    'support_vector_machine'\n",
        "]\n",
        "\n",
        "# TODO: Create figure with figsize=(20, 5)\n",
        "fig = None\n",
        "\n",
        "# TODO: Enumerate through methods with index\n",
        "\n",
        "\n",
        "    # Instantiate model\n",
        "    if method == 'perceptron':\n",
        "\n",
        "        # TODO: Instantiate perceptron model with tolerance of 1e-1 and alpha of 0\n",
        "        model = None\n",
        "\n",
        "    elif method == 'logistic_regression':\n",
        "\n",
        "        # TODO: Instantiate logistic regression model with tolerance of 1e-1\n",
        "        model = None\n",
        "\n",
        "    elif method == 'support_vector_machine':\n",
        "\n",
        "        # TODO: Instantiate SVC (Support Vector Machine Classifier) with tolerance of 1e-1 and C=1e10 (simulates a hard-SVM) using a linear kernel\n",
        "        model = None\n",
        "\n",
        "    else:\n",
        "        raise ValueError('Unsupported method: {}'.format(method))\n",
        "\n",
        "    # TODO: Train the model\n",
        "\n",
        "\n",
        "    # TODO: Get x1_min and x1_max (0-th dimension), and x2_min and x2_max (1-st dimension) from X\n",
        "    x1_min, x1_max = None, None\n",
        "    x2_min, x2_max = None, None\n",
        "\n",
        "    # TODO: Create 2 linspaces: one from x1_min to x1_max and the other from x1_min to x2_max with 500 units\n",
        "    x1_linspace = None\n",
        "    x2_linspace = None\n",
        "\n",
        "    # TODO: Create meshgrid for x1 and x2 using linspaces\n",
        "    x1, x2 = None, None\n",
        "\n",
        "    # TODO: Predict values for every point in meshgrid\n",
        "    all_Xs = None\n",
        "    y_hat = None\n",
        "\n",
        "    # TODO: Reshape y_hat to x1 or x2's shape\n",
        "    y_hat = None\n",
        "\n",
        "    # TODO: Instantiate axis for subplot of a 1 x 3 figure\n",
        "    ax = None\n",
        "\n",
        "    # TODO: Plot Contour for predictions with levels=20, cmap='coolwarm', alpha=0.8, vmin=-3, vmax=3\n",
        "    contour = None\n",
        "\n",
        "    # TODO: Create colorbar for contour on axis and set its label to 'y_hat'\n",
        "    cbar = None\n",
        "\n",
        "\n",
        "    # TODO: Plot decision boundary using levels=[0], colors='black', linewidths=2\n",
        "    decision_boundary = None\n",
        "\n",
        "    # TODO: Create scatter plot for X and set its color to y with edgecolor='black', cmap='coolwarm', label='Ground truth'\n",
        "\n",
        "\n",
        "    # TODO: If support vector machine\n",
        "    # Create scatter plot of support vectors with s=100, facecolors='none', edgecolors='green', label='Support Vectors'\n",
        "\n",
        "\n",
        "    # TODO: Set title to ''Decision boundary for {}'\n",
        "\n",
        "\n",
        "    # TODO: Set xlabel to 'x1'\n",
        "\n",
        "\n",
        "    # TODO: Set ylabel to 'x2'\n",
        "\n",
        "\n",
        "    # TODO: Set legend with loc='upper right'\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Sqm_di8gWhsa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load datasets"
      ],
      "metadata": {
        "id": "TTvfLetIQmk5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load datasets\n",
        "datasets = [\n",
        "    skdata.load_iris(),\n",
        "    skdata.load_breast_cancer(),\n",
        "    skdata.load_digits(),\n",
        "    skdata.load_wine()\n",
        "]\n",
        "\n",
        "dataset_names = [\n",
        "    'Iris',\n",
        "    'Breast cancer',\n",
        "    'Digits',\n",
        "    'Wine'\n",
        "]"
      ],
      "metadata": {
        "id": "k9OD26CBQmHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compare Perceptron, Logistic Regression, and Support Vector Machines across all datasets"
      ],
      "metadata": {
        "id": "Ibd3k8JeQvHO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define lists to hold validation scores across trials\n",
        "scores_val = {\n",
        "    'perceptron' : [],\n",
        "    'logistic_regression': [],\n",
        "    'support_vector_machine' : []\n",
        "}\n",
        "\n",
        "# Perform 10 trials of experiments\n",
        "n_trial = 10\n",
        "\n",
        "for n in range(n_trial):\n",
        "\n",
        "    print('***** TRIAL {} *****\\n'.format(n))\n",
        "\n",
        "    # Zip up all dataset options\n",
        "    dataset_options = zip(\n",
        "        datasets,\n",
        "        dataset_names)\n",
        "\n",
        "    for dataset, dataset_name in dataset_options:\n",
        "\n",
        "        '''\n",
        "        Create the training and validation splits\n",
        "        '''\n",
        "        X = dataset.data\n",
        "        y = dataset.target\n",
        "\n",
        "        print('Preprocessing the {} dataset ({} samples, {} feature dimensions)'.format(dataset_name, X.shape[0], X.shape[1]))\n",
        "\n",
        "        # Shuffle the dataset based on sample indices\n",
        "        shuffled_indices = np.random.permutation(X.shape[0])\n",
        "\n",
        "        # Choose the first 80% as training set and the next 20% as validation\n",
        "        train_split_idx = int(0.80 * X.shape[0])\n",
        "\n",
        "        train_indices = shuffled_indices[0:train_split_idx]\n",
        "        val_indices = shuffled_indices[train_split_idx:]\n",
        "\n",
        "        # Select the examples from X and y to construct our training and validation sets\n",
        "        X_train, y_train = X[train_indices, :], y[train_indices]\n",
        "        X_val, y_val = X[val_indices, :], y[val_indices]\n",
        "\n",
        "        for method in ['perceptron', 'logistic_regression', 'support_vector_machine']:\n",
        "\n",
        "            print('***** Experiments on the {} dataset using {} model *****'.format(\n",
        "                dataset_name,\n",
        "                method))\n",
        "\n",
        "            # Instantiate model\n",
        "            if method == 'perceptron':\n",
        "\n",
        "                # TODO: Instantiate perceptron model with tolerance of 1e-1 and alpha of 0\n",
        "                model = None\n",
        "\n",
        "            elif method == 'logistic_regression':\n",
        "\n",
        "                # TODO: Instantiate logistic regression model with tolerance of 1e-1\n",
        "                model = None\n",
        "\n",
        "            elif method == 'support_vector_machine':\n",
        "\n",
        "                # TODO: Instantiate SVC (Support Vector Machine Classifier) with tolerance of 1e-1 and C=1 (soft SVM) using a linear kernel\n",
        "                model = None\n",
        "\n",
        "            else:\n",
        "                raise ValueError('Unsupported method: {}'.format(method))\n",
        "\n",
        "\n",
        "            # TODO: Train the model\n",
        "\n",
        "\n",
        "            # TODO: Score model using mean accuracy on training set\n",
        "            predictions_train = None\n",
        "            score_train = None\n",
        "            print('Training set mean accuracy: {:.4f}'.format(score_train))\n",
        "\n",
        "            # TODO: Score model using mean accuracy validation set\n",
        "            predictions_val = None\n",
        "            score_val = None\n",
        "            print('Validation set mean accuracy: {:.4f}'.format(score_val))\n",
        "\n",
        "            # TODO: Append score to validation scores for the given method\n",
        "\n",
        "\n",
        "        print('')\n",
        "\n",
        "# TODO: Compute mean over trials for each method\n",
        "mean_scores_val_perceptron = None\n",
        "mean_scores_val_logistic = None\n",
        "mean_scores_val_svm = None\n",
        "\n",
        "print('***** Mean accuracy across {} trials *****'.format(n_trial))\n",
        "\n",
        "print('Perceptron: {}'.format(mean_scores_val_perceptron))\n",
        "print('Logistic Regression: {}'.format(mean_scores_val_logistic))\n",
        "print('Support Vector Machine: {}'.format(mean_scores_val_svm))"
      ],
      "metadata": {
        "id": "yB29ajtrK8sQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}