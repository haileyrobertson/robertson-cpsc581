{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WYwyrVHN7iO"
      },
      "source": [
        "**Exercise 11: Image classification with Neural Networks**\n",
        "\n",
        "*CPSC 381/581: Machine Learning*\n",
        "\n",
        "*Yale University*\n",
        "\n",
        "*Instructor: Alex Wong*\n",
        "\n",
        "*Student: Hailey Robertson*\n",
        "\n",
        "**Prerequisites**:\n",
        "\n",
        "1. Enable Google Colaboratory as an app on your Google Drive account\n",
        "\n",
        "2. Create a new Google Colab notebook, this will also create a \"Colab Notebooks\" directory under \"MyDrive\" i.e.\n",
        "```\n",
        "/content/drive/MyDrive/Colab Notebooks\n",
        "```\n",
        "\n",
        "3. Create the following directory structure in your Google Drive\n",
        "```\n",
        "/content/drive/MyDrive/Colab Notebooks/CPSC 381-581: Machine Learning/Exercises\n",
        "```\n",
        "\n",
        "4. Move the 11_exercise_exercise_image_classification.ipynb into\n",
        "```\n",
        "/content/drive/MyDrive/Colab Notebooks/CPSC 381-581: Machine Learning/Exercises\n",
        "```\n",
        "so that its absolute path is\n",
        "```\n",
        "/content/drive/MyDrive/Colab Notebooks/CPSC 381-581: Machine Learning/Exercises/11_exercise_exercise_image_classification.ipynb\n",
        "```\n",
        "\n",
        "5. Prior to starting this exercise, please create a directory called 'data' within your 'Exercises' directory and within 'data' create a directory called 'exercise_11', i.e.\n",
        "```\n",
        "/content/drive/MyDrive/Colab Notebooks/CPSC 381-581: Machine Learning/Exercises/data/exercise_11\n",
        "```\n",
        "\n",
        "6. Set up GPU runtime by selecting `Runtime` on the top tool bar, then selecting `Change runtime type` in the drop-down menu, selecting `GPU` under Hardware accelerator and clicking `Save`.\n",
        "\n",
        "\n",
        "\n",
        "In this exercise, we will create a simple neural network model and a logistic regression model for classifying images. We will experiment with learning rate, batch size, and different configurations of layers within the network. We will demonstrate this on the CIFAR-10 dataset. Note: Accuracy of Neural Network should exceed 52%.\n",
        "\n",
        "**Submission**:\n",
        "\n",
        "1. Implement all TODOs in the code blocks below.\n",
        "\n",
        "2. Report your training and testing scores.\n",
        "\n",
        "```\n",
        "Report training and testing scores here.\n",
        "\n",
        "```\n",
        "\n",
        "3. List any collaborators.\n",
        "\n",
        "```\n",
        "Collaborators: N/A\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjvZjKr-N_qh"
      },
      "source": [
        "Import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0VFIdrB0u58",
        "outputId": "77b5f525-bb89-41b5-ab9b-ae54089013b3"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# from google.colab import auth\n",
        "# from google.auth import default\n",
        "import os\n",
        "\n",
        "# drive.mount('/content/drive/', force_remount=True)\n",
        "# os.chdir('/content/drive/MyDrive/Colab Notebooks/CPSC 381-581: Machine Learning/Exercises')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "oGW3cccIofOE"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch, torchvision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pft5E9Cy4w4I"
      },
      "source": [
        "Hyper-parameters for training neural network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uZzL5RcuTJQa"
      },
      "outputs": [],
      "source": [
        "# TODO: Choose hyper-parameters\n",
        "\n",
        "# Model - either neural network or logistic regression\n",
        "MODEL_NAME = 'neural_network'\n",
        "\n",
        "# Batch size - number of images within a training batch of one training iteration\n",
        "N_BATCH = 64\n",
        "\n",
        "# Training epoch - number of passes through the full training dataset\n",
        "N_EPOCH = 10\n",
        "\n",
        "# Learning rate - step size to update parameters\n",
        "LEARNING_RATE = 0.01\n",
        "\n",
        "# Learning rate decay - scaling factor to decrease learning rate at the end of each decay period\n",
        "LEARNING_RATE_DECAY = 0.9\n",
        "\n",
        "# Learning rate decay period - number of epochs before reducing/decaying learning rate\n",
        "LEARNING_RATE_DECAY_PERIOD = 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHOCFhqgVtO8"
      },
      "source": [
        "Define Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9YxBsFGBost_"
      },
      "outputs": [],
      "source": [
        "class NeuralNetwork(torch.nn.Module):\n",
        "    '''\n",
        "    Neural network class of fully connected layers\n",
        "\n",
        "    Arg(s):\n",
        "        n_input_feature : int\n",
        "            number of input features\n",
        "        n_output : int\n",
        "            number of output classes\n",
        "    '''\n",
        "\n",
        "    def __init__(self, n_input_feature, n_output):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "\n",
        "        # Create your 6-layer neural network using fully connected layers with ReLU activations\n",
        "        # https://pytorch.org/docs/stable/generated/torch.nn.Linear.html\n",
        "        # https://pytorch.org/docs/stable/generated/torch.nn.functional.relu.html\n",
        "        # https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html\n",
        "\n",
        "        # DONE: Instantiate 5 fully connected layers\n",
        "        self.fully_connected_layer_1 = torch.nn.Linear(n_input_feature, 512)\n",
        "        self.fully_connected_layer_2 = torch.nn.Linear(512, 256)\n",
        "        self.fully_connected_layer_3 = torch.nn.Linear(256, 128)\n",
        "        self.fully_connected_layer_4 = torch.nn.Linear(128, 64)\n",
        "        self.fully_connected_layer_5 = torch.nn.Linear(64, 32)\n",
        "\n",
        "        # DONE: Define output layer\n",
        "        self.output = torch.nn.Linear(32, n_output)\n",
        "\n",
        "    def forward(self, x):\n",
        "        '''\n",
        "        Forward pass through the neural network\n",
        "\n",
        "        Arg(s):\n",
        "            x : torch.Tensor[float32]\n",
        "                tensor of N x d\n",
        "        Returns:\n",
        "            torch.Tensor[float32]\n",
        "                tensor of n_output predicted class\n",
        "        '''\n",
        "\n",
        "        # DONE?: Implement forward function\n",
        "        output_fc1 = torch.relu(self.fully_connected_layer_1(x))\n",
        "        output_fc2 = torch.relu(self.fully_connected_layer_2(output_fc1))\n",
        "        output_fc3 = torch.relu(self.fully_connected_layer_3(output_fc2))\n",
        "        output_fc4 = torch.relu(self.fully_connected_layer_4(output_fc3))\n",
        "        output_fc5 = torch.relu(self.fully_connected_layer_5(output_fc4))\n",
        "\n",
        "        output_logits = self.output(output_fc5)\n",
        "\n",
        "        return output_logits\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rw2cyDGfw5kE"
      },
      "outputs": [],
      "source": [
        "class LogisticRegression(torch.nn.Module):\n",
        "    '''\n",
        "    Logistic regression class\n",
        "\n",
        "    Arg(s):\n",
        "        n_input_feature : int\n",
        "            number of input features\n",
        "        n_output : int\n",
        "            number of output classes\n",
        "    '''\n",
        "\n",
        "    def __init__(self, n_input_feature, n_output):\n",
        "        super(LogisticRegression, self).__init__()\n",
        "\n",
        "        # Create your logistic regression model using a fully connected layer\n",
        "        # https://pytorch.org/docs/stable/generated/torch.nn.Linear.html\n",
        "\n",
        "        # DONE: Define linear layer\n",
        "        self.linear = torch.nn.Linear(n_input_feature, n_output)\n",
        "\n",
        "    def forward(self, x):\n",
        "        '''\n",
        "        Forward pass through the neural network\n",
        "\n",
        "        Arg(s):\n",
        "            x : torch.Tensor[float32]\n",
        "                tensor of N x d\n",
        "        Returns:\n",
        "            torch.Tensor[float32]\n",
        "                tensor of n_output predicted class\n",
        "        '''\n",
        "\n",
        "        # DONE: Implement forward function\n",
        "        output_logits = self.linear(x)\n",
        "\n",
        "        return output_logits\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdnyLTLbZxTb"
      },
      "source": [
        "Define training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zTEHZSxEZxsE"
      },
      "outputs": [],
      "source": [
        "def train(model,\n",
        "          dataloader,\n",
        "          n_epoch,\n",
        "          optimizer,\n",
        "          learning_rate_decay,\n",
        "          learning_rate_decay_period,\n",
        "          device):\n",
        "    '''\n",
        "    Trains the model using optimizer and specified learning rate schedule\n",
        "\n",
        "    Arg(s):\n",
        "        model : torch.nn.Module\n",
        "            neural network or logistic regression\n",
        "        dataloader : torch.utils.data.DataLoader\n",
        "            # https://pytorch.org/docs/stable/data.html\n",
        "            dataloader for training data\n",
        "        n_epoch : int\n",
        "            number of epochs to train\n",
        "        optimizer : torch.optim\n",
        "            https://pytorch.org/docs/stable/optim.html\n",
        "            optimizer to use for updating weights\n",
        "        learning_rate_decay : float\n",
        "            rate of learning rate decay\n",
        "        learning_rate_decay_period : int\n",
        "            period to reduce learning rate based on decay e.g. every 2 epoch\n",
        "        device : str\n",
        "            device to run on\n",
        "    Returns:\n",
        "        torch.nn.Module : trained network\n",
        "    '''\n",
        "\n",
        "    device = 'cuda' if device == 'gpu' or device == 'cuda' else 'cpu'\n",
        "    device = torch.device(device)\n",
        "\n",
        "    # DONE: Move model to device using .to()\n",
        "    model = model.to(device)\n",
        "\n",
        "    # DONE: Define cross entropy loss (note: torch.nn.CrossEntropyLoss takes logits as inputs)\n",
        "    # https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html\n",
        "    loss_func = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    for epoch in range(n_epoch):\n",
        "\n",
        "        # Accumulate total loss for each epoch\n",
        "        total_loss = 0.0\n",
        "\n",
        "        # DONE: Decrease learning rate when learning rate decay period is met\n",
        "        # Directly modify param_groups in optimizer to set new learning rate\n",
        "        # e.g. decrease learning rate by a factor of decay rate every 2 epoch\n",
        "        if epoch % learning_rate_decay_period == 0 and epoch != 0:\n",
        "            for param_group in optimizer.param_groups:\n",
        "                param_group['lr'] *= learning_rate_decay\n",
        "\n",
        "        # DONE?: Enumerate through batches of (images, labels) from dataloader\n",
        "        for images, labels in dataloader:\n",
        "\n",
        "            # DONE: Move images and labels to device using .to()\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # DONE?: Vectorize images from (N, H, W, C) to (N, d)\n",
        "            n_dim = images.shape[1] * images.shape[2] * images.shape[3]\n",
        "            images = images.view(-1, n_dim)\n",
        "\n",
        "            # DONE: Forward through the model\n",
        "            outputs = model(images)\n",
        "\n",
        "            # DONE: Clear gradients so we don't accumlate them from previous batches\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # DONE: Compute loss function\n",
        "            loss = loss_func(outputs, labels)\n",
        "\n",
        "            # DONE: Update parameters by backpropagation\n",
        "            loss.backward()\n",
        "\n",
        "            # DONE: Accumulate total loss for the epoch\n",
        "            total_loss = total_loss + loss.item()\n",
        "\n",
        "        # DONE: Compute average loss for the epoch\n",
        "        mean_loss = total_loss / len(dataloader)\n",
        "\n",
        "        # Log average loss over the epoch\n",
        "        print('Epoch={}/{}  Loss: {:.3f}'.format(epoch + 1, n_epoch, mean_loss))\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XKF-hNYa7ea"
      },
      "source": [
        "Define evaluation loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pa7O3vsuZ9S7"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, dataloader, class_names, device):\n",
        "    '''\n",
        "    Evaluates the network on a dataset\n",
        "\n",
        "    Arg(s):\n",
        "        model : torch.nn.Module\n",
        "            neural network or logistic regression\n",
        "        dataloader : torch.utils.data.DataLoader\n",
        "            # https://pytorch.org/docs/stable/data.html\n",
        "            dataloader for training data\n",
        "        class_names : list[str]\n",
        "            list of class names to be used in plot\n",
        "        device : str\n",
        "            device to run on\n",
        "    '''\n",
        "\n",
        "    device = 'cuda' if device == 'gpu' or device == 'cuda' else 'cpu'\n",
        "    device = torch.device(device)\n",
        "\n",
        "    # DONE: Move model to device using .to()\n",
        "    model = model.to(device)\n",
        "\n",
        "    n_correct = 0\n",
        "    n_sample = 0\n",
        "\n",
        "    # Make sure we do not backpropagate\n",
        "    with torch.no_grad():\n",
        "\n",
        "        # DONE: Iterate through samples (images, labels) from dataloader\n",
        "        for images, labels in dataloader:\n",
        "\n",
        "            # DONE: Move images and labels to device using .to()\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # DONE: Vectorize images from (N, H, W, C) to (N, d)\n",
        "            n_dim = images.shape[1] * images.shape[2] * images.shape[3]\n",
        "            images = images.view(-1, n_dim)\n",
        "\n",
        "            # DONE: Forward through the model\n",
        "            outputs = model(images)\n",
        "\n",
        "            # DONE?: Take the argmax over the outputs\n",
        "            outputs = torch.argmax(outputs, dim=1)\n",
        "\n",
        "            # DONE?: Accumulate number of samples\n",
        "            # maybe labels.size(0) \n",
        "            n_sample = n_sample + labels.shape[0]\n",
        "\n",
        "            # DONE?: Check if our prediction is correct\n",
        "            n_correct = n_correct + torch.sum(outputs == labels).item()\n",
        "\n",
        "    # DONE: Compute mean accuracy\n",
        "    mean_accuracy = (n_correct / n_sample) * 100\n",
        "\n",
        "    print('Mean accuracy over {} images: {:.3f}%'.format(n_sample, mean_accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMVEF-Ajn691"
      },
      "source": [
        "Training a neural network and logistic regression for image classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LxKRWZZQn5VY"
      },
      "outputs": [],
      "source": [
        "# Create transformations convert data to torch tensor\n",
        "# https://pytorch.org/docs/stable/torchvision/transforms.html\n",
        "transforms = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Set path to save checkpoint\n",
        "checkpoint_path = './checkpoint-{}.pth'.format(MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8byUq18XoAN-"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Set up dataloading\n",
        "'''\n",
        "# Download and setup CIFAR10 training set using preconfigured torchvision.datasets.CIFAR10\n",
        "cifar10_train = torchvision.datasets.CIFAR10(\n",
        "    root=os.path.join('data', 'exercise_11'),\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transforms)\n",
        "\n",
        "# DONE?: Setup a dataloader (iterator) to fetch from the training set using\n",
        "# torch.utils.data.DataLoader and set shuffle=True, drop_last=True, num_workers=2\n",
        "# Set your batch size to the hyperparameter N_BATCH\n",
        "dataloader_train = torch.utils.data.DataLoader(\n",
        "    cifar10_train,\n",
        "    batch_size=N_BATCH,\n",
        "    shuffle=True,\n",
        "    drop_last=True,\n",
        "    num_workers=2)\n",
        "\n",
        "# Define the possible classes in CIFAR10\n",
        "class_names = [\n",
        "    'plane',\n",
        "    'car',\n",
        "    'bird',\n",
        "    'cat',\n",
        "    'deer',\n",
        "    'dog',\n",
        "    'frog',\n",
        "    'horse',\n",
        "    'ship',\n",
        "    'truck'\n",
        "]\n",
        "\n",
        "# CIFAR10 has 10 classes\n",
        "n_class = len(class_names)\n",
        "\n",
        "'''\n",
        "Set up model and optimizer\n",
        "'''\n",
        "# DONE: Compute number of input features. Hint: They are RGB images of size 32 x 32\n",
        "n_input_feature = 3 * 32 * 32\n",
        "\n",
        "if MODEL_NAME == 'neural_network':\n",
        "    # DONE: Instantiate neural network\n",
        "    model = NeuralNetwork(n_input_feature, n_class)\n",
        "elif MODEL_NAME == 'logistic_regression':\n",
        "    # DONE: Instantiate logistic regression\n",
        "    model = LogisticRegression(n_input_feature, n_class)\n",
        "else:\n",
        "    raise('Unsupported model name: {}'.format(MODEL_NAME))\n",
        "\n",
        "print('Training {} model'.format(MODEL_NAME))\n",
        "\n",
        "# DONE?: Setup learning rate SGD optimizer and step function scheduler\n",
        "# https://pytorch.org/docs/stable/optim.html?#torch.optim.SGD\n",
        "optimizer = torch.optim.SGD(\n",
        "    model.parameters(),\n",
        "    lr=LEARNING_RATE)\n",
        "\n",
        "'''\n",
        "Train model and store weights\n",
        "'''\n",
        "# DONE: Set model to training mode\n",
        "model.train()\n",
        "\n",
        "# DONE: Train model with device='cuda'\n",
        "model = train(\n",
        "    model=model,\n",
        "    dataloader=dataloader_train,\n",
        "    n_epoch=N_EPOCH,\n",
        "    optimizer=optimizer,\n",
        "    learning_rate_decay=LEARNING_RATE_DECAY,\n",
        "    learning_rate_decay_period=LEARNING_RATE_DECAY_PERIOD,\n",
        "    device='cuda')\n",
        "\n",
        "# DONE: Save weights into checkpoint path\n",
        "torch.save(model.state_dict(), checkpoint_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WubtddGkwiSo"
      },
      "source": [
        "Testing the trained neural network on image classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KByIHECHA3m6"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Set up dataloading\n",
        "'''\n",
        "# TODO: Download and setup CIFAR10 testing set using\n",
        "# preconfigured torchvision.datasets.CIFAR10\n",
        "cifar10_test = None\n",
        "\n",
        "# TODO: Setup a dataloader (iterator) to fetch from the testing set using\n",
        "# torch.utils.data.DataLoader and set shuffle=False, drop_last=False, num_workers=2\n",
        "# Set batch_size to 25\n",
        "dataloader_test = None\n",
        "\n",
        "'''\n",
        "Set up model\n",
        "'''\n",
        "# TODO: Compute number of input features. Hint: They are RGB images of size 32 x 32\n",
        "n_input_feature = None\n",
        "\n",
        "if MODEL_NAME == 'neural_network':\n",
        "    # TODO: Instantiate neural network\n",
        "    model = None\n",
        "elif MODEL_NAME == 'logistic_regression':\n",
        "    # TODO: Instantiate logistic regression\n",
        "    model = None\n",
        "else:\n",
        "    raise('Unsupported model name: {}'.format(MODEL_NAME))\n",
        "\n",
        "print('Evaluating {} model from {}'.format(MODEL_NAME, checkpoint_path))\n",
        "\n",
        "'''\n",
        "Restore weights and evaluate model\n",
        "'''\n",
        "# TODO: Load model from checkpoint\n",
        "checkpoint = None\n",
        "\n",
        "\n",
        "# TODO: Set model to evaluation mode\n",
        "\n",
        "\n",
        "# TODO: Evaluate model on testing set with device='cuda'\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
