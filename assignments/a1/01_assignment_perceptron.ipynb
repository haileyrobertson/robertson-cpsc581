{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r37l-FPc9o0h"
      },
      "source": [
        "**Assignment 1: Perceptron**\n",
        "\n",
        "*CPSC 381/581: Machine Learning*\n",
        "\n",
        "*Yale University*\n",
        "\n",
        "*Instructor: Alex Wong*\n",
        "\n",
        "*Student: Hailey Robertson, hdr22*\n",
        "\n",
        "\n",
        "**Prerequisites**:\n",
        "\n",
        "1. Enable Google Colaboratory as an app on your Google Drive account\n",
        "\n",
        "2. Create a new Google Colab notebook, this will also create a \"Colab Notebooks\" directory under \"MyDrive\" i.e.\n",
        "```\n",
        "/content/drive/MyDrive/Colab Notebooks\n",
        "```\n",
        "\n",
        "3. Create the following directory structure in your Google Drive\n",
        "```\n",
        "/content/drive/MyDrive/Colab Notebooks/CPSC 381-581: Machine Learning/Assignments\n",
        "```\n",
        "\n",
        "4. Move the 01_assignment_perceptron_multiclass.ipynb into\n",
        "```\n",
        "/content/drive/MyDrive/Colab Notebooks/CPSC 381-581: Machine Learning/Assignments\n",
        "```\n",
        "so that its absolute path is\n",
        "```\n",
        "/content/drive/MyDrive/Colab Notebooks/CPSC 381-581: Machine Learning/Assignments/01_assignment_perceptron.ipynb\n",
        "```\n",
        "\n",
        "In this assignment, you will implement both binary and multiclass perceptron classifiers from scratch.\n",
        "You will test your implementations on the digits dataset from scikit-learn. The assignment is divided\n",
        "into three main parts:\n",
        "\n",
        "1. Implementing a binary perceptron for digit classification (0 vs 1)\n",
        "2. Implementing a multiclass perceptron for full digits classification (0-9)\n",
        "3. Comparing your implementations with scikit-learn's Perceptron\n",
        "\n",
        "\n",
        "**Submission**:\n",
        "\n",
        "1. Implement all TODOs in the code blocks below.\n",
        "\n",
        "2. Report your validation and testing scores. For full credit, your testing scores should be higher than 0.9.\n",
        "\n",
        "```\n",
        "Report validation and testing scores here.\n",
        "```\n",
        "\n",
        "3. List any collaborators.\n",
        "\n",
        "```\n",
        "Collaborators: None.\n",
        "\n",
        "Collaboration details: N/A.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "koDraeo69YZH"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import sklearn.datasets as skdata\n",
        "from sklearn.linear_model import Perceptron\n",
        "import sklearn.metrics as skmetrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "import warnings, time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "warnings.filterwarnings(action='ignore')\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eLtgw7_h0ewd"
      },
      "outputs": [],
      "source": [
        "class BinaryPerceptron:\n",
        "    '''\n",
        "    Implementation of Binary Perceptron\n",
        "    '''\n",
        "\n",
        "    def __init__(self):\n",
        "        self.__weights = None\n",
        "\n",
        "    def __update(self, x, y):\n",
        "        '''\n",
        "        Update weights for misclassified examples\n",
        "\n",
        "        Arg(s):\n",
        "            x : numpy.ndarray\n",
        "                Feature vector of shape d x 1\n",
        "            y : int\n",
        "                Label/target (-1 or 1)\n",
        "        '''\n",
        "\n",
        "        # DONE: Implement weight update rule for binary perceptron\n",
        "        self.__weights += x * y\n",
        "\n",
        "\n",
        "    def fit(self, x, y, max_iter=100):\n",
        "        '''\n",
        "        Fit the binary perceptron to training data\n",
        "\n",
        "        Arg(s):\n",
        "            x : numpy.ndarray\n",
        "                Features of shape d x N\n",
        "            y : numpy.ndarray\n",
        "                Labels/targets of shape 1 x N\n",
        "            max_iter : int\n",
        "                Maximum number of iterations\n",
        "        '''\n",
        "\n",
        "        n_features, n_samples = x.shape\n",
        "\n",
        "        # DONE: Initialize weights (including a bias term, w0) as zeros vector with shape d+1 x 1\n",
        "        self.__weights = np.zeros((n_features + 1, 1))\n",
        "\n",
        "        # DONE: Append artificial coordinate (x0) to the data\n",
        "        # Use ones to shift decision boundary\n",
        "        x = np.concatenate((np.ones((1, n_samples)), x), axis=0)\n",
        "\n",
        "        # DONE: Implement training loop\n",
        "\n",
        "        for _ in range(max_iter):\n",
        "            n_updates = 0\n",
        "\n",
        "            # Process each sample\n",
        "            for n in range(n_samples):\n",
        "                # DONE: Calculate prediction\n",
        "                x_n = x[:, n:n+1]\n",
        "                y_n = y[0, n]\n",
        "\n",
        "                prediction = np.sign(np.matmul(self.__weights.T, x_n))\n",
        "\n",
        "                if prediction == 0:\n",
        "                    prediction = 1\n",
        "                else:\n",
        "                    prediction\n",
        "\n",
        "                # DONE: Update weights if misclassified\n",
        "                if prediction != y_n:\n",
        "                    self.__update(x_n, y_n)\n",
        "                    n_updates += 1\n",
        "\n",
        "            # DONE: Break if no updates were made, e.g., check for convergence\n",
        "            if n_updates == 0:\n",
        "                break\n",
        "\n",
        "\n",
        "    def predict(self, x):\n",
        "        '''\n",
        "        Make predictions\n",
        "\n",
        "        Arg(s):\n",
        "            x : numpy.ndarray\n",
        "                Features of shape d x N\n",
        "\n",
        "        Returns:\n",
        "            numpy.ndarray : Predicted labels (-1 or 1) of 1 x N\n",
        "        '''\n",
        "\n",
        "        n_features, n_samples = x.shape\n",
        "\n",
        "        # DONE: Append artificial coordinate (x0) to the data\n",
        "        x = np.concatenate((np.ones((1, n_samples)), x), axis=0)\n",
        "\n",
        "        # DONE: Implement prediction logic\n",
        "        predictions = np.sign(np.matmul(self.__weights.T, x))\n",
        "        if predictions == 0:\n",
        "            predictions = 1\n",
        "        else:\n",
        "            predictions\n",
        "            \n",
        "        return predictions\n",
        "\n",
        "    def score(self, x, y):\n",
        "        '''\n",
        "        Calculate prediction accuracy\n",
        "\n",
        "        Arg(s):\n",
        "            x : numpy.ndarray\n",
        "                Features of shaped d x N\n",
        "            y : numpy.ndarray\n",
        "                Labels/targets of shape 1 x N\n",
        "\n",
        "        Returns:\n",
        "            float: Accuracy score\n",
        "        '''\n",
        "\n",
        "        # DONE: Implement accuracy calculation\n",
        "        predictions = self.predict(x)\n",
        "        accuracy = np.where(predictions == y, 1, 0)\n",
        "        mean_accuracy = np.mean(accuracy)\n",
        "        return mean_accuracy\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "U2GPCsDe0fJ8"
      },
      "outputs": [],
      "source": [
        "class MulticlassPerceptron:\n",
        "    '''\n",
        "    Implementation of Multiclass Perceptron using one-vs-rest strategy\n",
        "    '''\n",
        "\n",
        "    def __init__(self):\n",
        "        self.__weights = None\n",
        "        self.__n_classes = None\n",
        "\n",
        "    def __update(self, x, y, y_hat):\n",
        "        '''\n",
        "        Update weights for misclassified examples\n",
        "\n",
        "        Arg(s):\n",
        "            x : numpy.ndarray\n",
        "                Feature vector of shape d x 1\n",
        "            y : int\n",
        "                Label/target (-1 or 1)\n",
        "            y_hat : int\n",
        "                Predicted label (-1 or 1)\n",
        "        '''\n",
        "\n",
        "        # DONE: Implement weight update rule for multiclass case\n",
        "        self.__weights[:, y] += x.flatten()\n",
        "        self.__weights[:, y_hat] -= x.flatten()\n",
        "\n",
        "\n",
        "    def fit(self, x, y, max_iter=100):\n",
        "        '''\n",
        "        Fit the multiclass perceptron to training data\n",
        "\n",
        "        Arg(s):\n",
        "            x : numpy.ndarray)\n",
        "                Feature vector of shape d x N\n",
        "            y : numpy.ndarray\n",
        "                Label/target (-1 or 1) of shape 1 x N\n",
        "            max_iter : int\n",
        "                Maximum number of iterations\n",
        "        '''\n",
        "\n",
        "        n_features, n_samples = x.shape\n",
        "\n",
        "        # DONE: Get number of classes from unique values in y\n",
        "        self.__n_classes = len(np.unique(y))\n",
        "\n",
        "        # DONE: Initialize weights matrix of zeros with shape d+1 x C\n",
        "        self.__weights = np.zeros((n_features + 1, self.__n_classes))\n",
        "\n",
        "        # DONE: Append artificial coordinate (x0) to the data such that it is d+1 x N\n",
        "        x = np.concatenate((np.ones((1, n_samples)), x), axis=0)\n",
        "\n",
        "        # DONE: Implement training loop\n",
        "        for _ in range(max_iter):\n",
        "            n_updates = 0\n",
        "\n",
        "            # Process each sample\n",
        "            for n in range(n_samples):\n",
        "                x_n = x[:, n:n+1]\n",
        "                y_n = y[0, n]\n",
        "\n",
        "                # DONE: Calculate scores and make prediction for each class\n",
        "                scores = np.matmul(self.__weights.T, x_n).flatten()\n",
        "                y_hat = np.argmax(scores)\n",
        "\n",
        "                # Update if prediction is wrong\n",
        "                if y_hat != y_n:\n",
        "                    self.__update(x_n, y_n, y_hat)\n",
        "                    n_updates += 1\n",
        "\n",
        "            # DONE: Break if no updates were made, e.g., check for convergence\n",
        "            if n_updates == 0:\n",
        "                break\n",
        "\n",
        "\n",
        "    def predict(self, x):\n",
        "        '''\n",
        "        Make predictions on new data\n",
        "\n",
        "        Arg(s):\n",
        "            x : numpy.ndarray\n",
        "                Features of shape d x N\n",
        "\n",
        "        Returns:\n",
        "            numpy.ndarray : Predicted class labels\n",
        "        '''\n",
        "\n",
        "        n_features, n_samples = x.shape\n",
        "\n",
        "        # DONE: Append artificial coordinate (x0) to the data\n",
        "        x = np.concatenate((np.ones((1, n_samples)), x), axis=0)\n",
        "\n",
        "        scores = np.matmul(self.__weights.T, x)\n",
        "        predictions = np.argmax(scores, axis=0)\n",
        "\n",
        "        # DONE: Implement prediction logic for multiclass case\n",
        "        return predictions.reshape(1, -1)\n",
        "\n",
        "    def score(self, x, y):\n",
        "        '''\n",
        "        Calculate prediction accuracy\n",
        "\n",
        "        Arg(s):\n",
        "            x : numpy.ndarray\n",
        "                Features of shape d x N\n",
        "            y : numpy.ndarray\n",
        "                Label/target (-1 or 1) of shape 1 x N\n",
        "\n",
        "        Returns:\n",
        "            float : Accuracy score\n",
        "        '''\n",
        "\n",
        "        # DONE: Implement accuracy calculation\n",
        "        predictions = self.predict(x)\n",
        "        accuracy = np.where(predictions == y, 1, 0)\n",
        "        mean_accuracy = np.mean(accuracy)\n",
        "        return mean_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "TKDOpCsQ0fMi"
      },
      "outputs": [],
      "source": [
        "def prepare_binary_digits_data(digits_zero=0, digits_one=1):\n",
        "    '''\n",
        "    Prepare binary classification dataset from digits\n",
        "\n",
        "    Args:\n",
        "        digits_zero : int\n",
        "            First digit to classify\n",
        "        digits_one : int\n",
        "            Second digit to classify\n",
        "\n",
        "    Returns:\n",
        "        tuple: (X_train, y_train, X_val, y_val, X_test, y_test)\n",
        "            X_train : N x d\n",
        "            y_train : N x 1\n",
        "            X_val : M x d\n",
        "            y_val : M x 1\n",
        "            X_test : P x d\n",
        "            y_test : P x 1\n",
        "    '''\n",
        "\n",
        "    # Load digits dataset using sklearn.datasets\n",
        "    digits = skdata.load_digits()\n",
        "\n",
        "    # Select only the two specified digits\n",
        "    mask = np.isin(digits.target, [digits_zero, digits_one])\n",
        "    X = digits.data[mask]\n",
        "    y = digits.target[mask]\n",
        "\n",
        "    # Convert labels to -1/1\n",
        "    y = np.where(y == digits_zero, -1, 1)\n",
        "\n",
        "    # Split into train (60%), validation (20%), and test (20%) sets using random_state=42\n",
        "    X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42)\n",
        "\n",
        "    return X_train, np.expand_dims(y_train, axis=-1), X_val, np.expand_dims(y_val, axis=-1), X_test, np.expand_dims(y_test, axis=-1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "mj-dkbIU1MfE"
      },
      "outputs": [],
      "source": [
        "def prepare_multiclass_digits_data():\n",
        "    '''\n",
        "    Prepare multiclass classification dataset from digits\n",
        "\n",
        "    Returns:\n",
        "        tuple: (X_train, y_train, X_val, y_val, X_test, y_test)\n",
        "            X_train : N x d\n",
        "            y_train : N x 1\n",
        "            X_val : M x d\n",
        "            y_val : M x 1\n",
        "            X_test : P x d\n",
        "            y_test : P x 1\n",
        "    '''\n",
        "\n",
        "    # Load digits dataset using sklearn.datasets\n",
        "    digits = skdata.load_digits()\n",
        "    X, y = digits.data, digits.target\n",
        "\n",
        "    # Split into train (60%), validation (20%), and test (20%) sets with random_state=42\n",
        "    X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42)\n",
        "\n",
        "    return X_train, np.expand_dims(y_train, axis=-1), X_val, np.expand_dims(y_val, axis=-1), X_test, np.expand_dims(y_test, axis=-1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "b9TxySEH1Mh2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Binary Classification Experiment (0 vs 1)\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 73 is different from 217)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[25], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, max_iter\u001b[38;5;241m=\u001b[39mmax_iter)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# DONE: Calculate validation score\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m val_score \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMax iterations: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, Validation accuracy: \u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(max_iter, val_score))\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# DONE: Update best_model if current model performs better\u001b[39;00m\n",
            "Cell \u001b[0;32mIn[21], line 115\u001b[0m, in \u001b[0;36mBinaryPerceptron.score\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;124;03mCalculate prediction accuracy\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;124;03m    float: Accuracy score\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;66;03m# DONE: Implement accuracy calculation\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(predictions \u001b[38;5;241m==\u001b[39m y, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    117\u001b[0m mean_accuracy \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(accuracy)\n",
            "Cell \u001b[0;32mIn[21], line 92\u001b[0m, in \u001b[0;36mBinaryPerceptron.predict\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     89\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate((np\u001b[38;5;241m.\u001b[39mones((\u001b[38;5;241m1\u001b[39m, n_samples)), x), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# DONE: Implement prediction logic\u001b[39;00m\n\u001b[0;32m---> 92\u001b[0m predictions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msign(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__weights\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m predictions \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     94\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
            "\u001b[0;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 73 is different from 217)"
          ]
        }
      ],
      "source": [
        "# Binary classification experiment\n",
        "print(\"Binary Classification Experiment (0 vs 1)\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "labels = [0, 1]\n",
        "\n",
        "# Load and prepare binary data (0 vs 1)\n",
        "X_train, y_train, X_val, y_val, X_test, y_test = prepare_binary_digits_data(0, 1)\n",
        "\n",
        "# Try different max_iter values\n",
        "max_iters = [10, 50, 100]\n",
        "best_val_score = 0\n",
        "best_model = None\n",
        "\n",
        "\n",
        "for max_iter in max_iters:\n",
        "    # DONE: Initialize and train binary perceptron\n",
        "    model = BinaryPerceptron()\n",
        "    model.fit(X_train, y_train, max_iter=max_iter)\n",
        "\n",
        "    # DONE: Calculate validation score\n",
        "    val_score = model.score(X_val, y_val)\n",
        "    print(\"Max iterations: {}, Validation accuracy: {:.4f}\".format(max_iter, val_score))\n",
        "\n",
        "    # DONE: Update best_model if current model performs better\n",
        "    if val_score > best_val_score:\n",
        "        best_val_score = val_score\n",
        "        best_model = model\n",
        "\n",
        "\n",
        "# DONE: Test best model on test set\n",
        "test_score = best_model.score(X_test, y_test)\n",
        "print(\"\\nBest model test accuracy: {:.4f}\".format(test_score))\n",
        "\n",
        "# DONE: Create a confusion matrix using skmetrics.confusion_matrix for your model on the test set\n",
        "conf_matrix = skmetrics.confusion_matrix(y_test.flatten(), best_model.predict(X_test).flatten())\n",
        "\n",
        "# Show confusion matrix\n",
        "plt.show()\n",
        "time.sleep(1)\n",
        "\n",
        "# DONE: Compare with scikit-learn implementation by training with max_iter=10 and random_state=42 and testing on the test set\n",
        "sk_model = Perceptron(max_iter=10, random_state=42)\n",
        "sk_model.fit(X_train.T, y_train.flatten())\n",
        "\n",
        "sk_score = skmetrics.accuracy_score(y_test.flatten(), sk_model.predict(X_test.T))\n",
        "print(\"Scikit-learn Perceptron test accuracy: {:.4f}\".format(sk_score))\n",
        "\n",
        "# DONE: Create a confusion matrix using skmetrics.confusion_matrix for scikit model on the test set\n",
        "sk_conf_matrix = skmetrics.confusion_matrix(y_test.flatten(), sk_model.predict(X_test.T))\n",
        "\n",
        "# Show confusion matrix\n",
        "plt.show()\n",
        "time.sleep(1)\n",
        "\n",
        "\n",
        "print(\"\\nMulticlass Classification Experiment (0-9)\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "labels = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
        "\n",
        "# Load and prepare multiclass data\n",
        "X_train, y_train, X_val, y_val, X_test, y_test = prepare_multiclass_digits_data()\n",
        "\n",
        "# Try different max_iter values\n",
        "max_iters = [10, 50, 100]\n",
        "best_val_score = 0\n",
        "best_model = None\n",
        "\n",
        "for max_iter in max_iters:\n",
        "    # DONE: Initialize and train multiclass perceptron\n",
        "    model = MulticlassPerceptron(max_iter=max_iter, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # DONE: Calculate validation score\n",
        "    val_score = skmetrics.accuracy_score(y_val, model.predict(X_val))\n",
        "    print(\"Max iterations: {}, Validation accuracy: {:.4f}\".format(max_iter, val_score))\n",
        "\n",
        "    # DONE: Update best_model if current model performs better\n",
        "    if val_score > best_val_score:\n",
        "        best_val_score = val_score\n",
        "        best_model = model\n",
        "\n",
        "\n",
        "# DONE: Test best model on test set\n",
        "test_score = skmetrics.accuracy_score(y_test, best_model.predict(X_test))\n",
        "print(\"\\nBest model test accuracy: {:.4f}\".format(test_score))\n",
        "\n",
        "# DONE: Create a confusion matrix using skmetrics.confusion_matrix for your model on the test set\n",
        "conf_matrix = skmetrics.confusion_matrix(y_test, best_model.predict(X_test))\n",
        "\n",
        "\n",
        "# Show confusion matrix\n",
        "plt.show()\n",
        "time.sleep(1)\n",
        "\n",
        "# DONE: Compare with scikit-learn implementation by training with max_iter=10 and random_state=42 and testing on the test set\n",
        "sk_model = Perceptron(max_iter=10, random_state=42)\n",
        "sk_model.fit(X_train, y_train)\n",
        "\n",
        "sk_score = skmetrics.accuracy_score(y_test, sk_model.predict(X_test))\n",
        "print(\"Scikit-learn Perceptron test accuracy: {:.4f}\".format(sk_score))\n",
        "\n",
        "# TODO: Create a confusion matrix using skmetrics.confusion_matrix for your model on the test set\n",
        "sk_conf_matrix = skmetrics.confusion_matrix(y_test, sk_model.predict(X_test))\n",
        "\n",
        "# Show confusion matrix\n",
        "plt.show()\n",
        "time.sleep(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
